# Hierarchical Forecast Reconciliation with Uncertainty Quantification

A production-grade framework for hierarchical time series forecasting that combines statistical ensemble models (ETS + ARIMA) with probabilistic minimum trace (MinT) reconciliation to produce coherent forecasts across all hierarchy levels while preserving uncertainty quantification.

---

## Overview

Hierarchical time series arise naturally in domains such as retail, supply chain, and macroeconomics, where forecasts at different aggregation levels must be **coherent** -- that is, aggregate forecasts must equal the sum of their components. Naively producing independent forecasts at each level violates this constraint, leading to inconsistent planning and decision-making.

This project implements a principled approach that:

1. Trains an **ensemble of ETS and ARIMA** models on all bottom-level series
2. Aggregates forecasts through a **summation matrix** to all hierarchy levels
3. Applies **probabilistic MinT reconciliation** to enforce coherence while minimizing forecast variance
4. Propagates **prediction intervals** through the reconciliation process to maintain calibrated uncertainty estimates

### Key Features

- **Statistical Ensemble**: Weighted combination of Exponential Smoothing (ETS/Holt-Winters) and ARIMA (SARIMAX) models
- **Probabilistic MinT Reconciliation**: Minimum trace optimal reconciliation with WLS weights, preserving prediction intervals
- **11-Level Hierarchy**: Supports total, state, store, category, department, and all cross-level aggregations (693 total series)
- **Comprehensive Evaluation**: WRMSSE (M5 primary metric), MASE, sMAPE, coverage probability, interval scores, and coherence metrics
- **Experiment Tracking**: Integrated MLflow logging for reproducible experiments
- **Modular Architecture**: Extensible design supporting additional base forecasters and reconciliation methods

> **Note**: This project was trained and evaluated on **synthetic M5-style data** (490 item-store series, 365 days) generated by `scripts/generate_synthetic_data.py`. Results reflect synthetic data performance. Training on real M5 competition data from Kaggle would yield significantly different (and likely improved) results.

---

## Architecture

```
Synthetic M5 Hierarchical Data (490 bottom-level series, 365 days)
  │
  ▼
Data Pipeline: Load → Calendar/Price Features → Log1p → Outlier Handling → Z-Score Scaling
  │
  ▼
 ┌─────────────────┐     ┌─────────────────┐
 │       ETS        │     │     ARIMA        │
 │  (Holt-Winters)  │     │   (SARIMAX)      │
 │  490/490 fitted  │     │  490/490 fitted  │
 └────────┬────────┘     └────────┬────────┘
          │                       │
          ▼                       ▼
       Weighted Ensemble (50% ETS / 50% ARIMA)
          │
          ▼
       Bottom-Up Aggregation (S matrix: 693 × 490)
          │
          ▼
       MinT Reconciliation: G = S(S′WS)⁻¹S′W
          │
          ▼
 ┌────────────────────┬────────────────────┐
 │  Reconciled Point  │    Reconciled      │
 │  Forecasts (693)   │    Prediction      │
 │                    │    Intervals       │
 └────────────────────┴────────────────────┘
```

### Hierarchy Structure

The framework supports an 11-level hierarchy with 693 total series constructed from 490 bottom-level item-store combinations:

| Level | Description | Series Count |
|:------|:-----------|:------------:|
| Total | Grand total | 1 |
| State | CA, TX, WI | 3 |
| Store | 10 stores across 3 states | 10 |
| Category | HOBBIES, HOUSEHOLD, FOODS | 3 |
| Department | 7 departments | 7 |
| State × Category | Cross-level aggregation | 9 |
| State × Department | Cross-level aggregation | 21 |
| Store × Category | Cross-level aggregation | 30 |
| Store × Department | Cross-level aggregation | 70 |
| Item | 49 unique items | 49 |
| **Item × Store (bottom)** | **Bottom-level series** | **490** |
| | **Total** | **693** |

---

## Results

Training was performed on synthetic M5-style data with a 300-day training window, 28-day validation horizon, and 28-day test horizon.

### Model Training Summary

| Model | Series Fitted | Success Rate | Training Time |
|:------|:-------------|:------------:|:-------------:|
| ETS (Holt-Winters) | 490 / 490 | 100% | ~200s |
| ARIMA (SARIMAX) | 490 / 490 | 100% | ~1,670s |
| **Total Pipeline** | **980 / 980** | **100%** | **~1,871s** |

### Forecast Accuracy Metrics

| Metric | Value | Description |
|:-------|:-----:|:-----------|
| **WRMSSE** | **1.7262** | Weighted Root Mean Squared Scaled Error (M5 primary metric) |
| **MASE** | **3.0113** | Mean Absolute Scaled Error |
| **sMAPE** | **106.17%** | Symmetric Mean Absolute Percentage Error |

### Hierarchical Coherence

| Metric | Value |
|:-------|:-----:|
| **Coherence** | **1.000** |

All 693 reconciled forecasts are **perfectly coherent** -- aggregate-level forecasts exactly equal the sum of their constituent bottom-level forecasts at every level of the hierarchy.

### Uncertainty Quantification

| Metric | Value |
|:-------|:-----:|
| 90% Coverage | 33.9% |
| 95% Coverage | 35.3% |

### Interpretation

**Point Forecast Accuracy** -- A WRMSSE of 1.7262 indicates the ensemble forecasts are approximately 1.7x the error of a naive seasonal baseline. This is expected given that (a) the data is synthetic with a limited signal-to-noise ratio, (b) metrics are computed on transformed (log1p + z-score) scale, and (c) only statistical models are used without deep learning components.

**Perfect Coherence** -- The coherence score of 1.000 confirms that the bottom-up aggregation combined with MinT reconciliation produces forecasts that are perfectly consistent across all 11 hierarchy levels. This is the primary objective of hierarchical reconciliation.

**Uncertainty Coverage** -- The coverage values (33.9% and 35.3% for 90% and 95% targets, respectively) indicate that prediction intervals are narrower than ideal after reconciliation. This is a known limitation: MinT applies a linear transformation to interval bounds that can compress them when base forecasts are already coherent through bottom-up construction. Sample-based reconciliation methods would better preserve interval calibration.

**Proof-of-Concept Scope** -- These results are on synthetic data designed to validate the framework's correctness and coherence guarantees. Training on real M5 competition data would produce substantially different accuracy metrics, as real retail sales exhibit richer seasonal patterns, promotions effects, and cross-series correlations that statistical models can better exploit.

---

## Methodology

### Probabilistic MinT Reconciliation

The core innovation is the application of minimum trace (MinT) reconciliation ([Wickramasuriya et al., 2019](https://doi.org/10.1080/01621459.2018.1448825)) with uncertainty propagation:

1. **Base Forecasts**: ETS and ARIMA models are independently fitted to all 490 bottom-level series, producing point forecasts and prediction intervals
2. **Ensemble Combination**: Forecasts are combined via weighted averaging (50/50 split) with bootstrap uncertainty propagation (1,000 samples)
3. **Bottom-Up Aggregation**: The summation matrix **S** (693 x 490) maps bottom-level forecasts to all hierarchy levels
4. **MinT Reconciliation**: The reconciliation matrix **G** = **S**(**S**'**W****S**)^(-1)**S**'**W** adjusts forecasts to minimize total variance while enforcing coherence, where **W** is estimated from forecast error covariances using WLS
5. **Interval Propagation**: Prediction intervals are transformed through the same linear mapping **G** to maintain probabilistic consistency

### Ensemble Design

| Component | Configuration |
|:----------|:-------------|
| ETS | Holt-Winters exponential smoothing with additive trend and seasonality |
| ARIMA | SARIMAX with automatic order selection |
| Weights | 50% ETS / 50% ARIMA (configurable) |
| Combination | Weighted average of point forecasts; bootstrap combination of intervals |

---

## Installation

```bash
git clone https://github.com/A-SHOJAEI/hierarchical-forecast-reconciliation-with-uncertainty-quantification.git
cd hierarchical-forecast-reconciliation-with-uncertainty-quantification
pip install -e .
```

### Requirements

- Python 3.8+
- Core: `statsmodels`, `scipy`, `scikit-learn`, `pandas`, `numpy`
- Tracking: `mlflow`, `optuna`
- Visualization: `matplotlib`, `seaborn`, `plotly`

Full dependency list in [`requirements.txt`](requirements.txt) and [`pyproject.toml`](pyproject.toml).

---

## Usage

### 1. Generate Synthetic Data

```bash
python scripts/generate_synthetic_data.py
```

Generates synthetic M5-style hierarchical time series data with 490 bottom-level series across 365 days.

### 2. Train the Ensemble

```bash
python scripts/train.py --config configs/default.yaml
```

Fits ETS and ARIMA models on all bottom-level series, builds the hierarchy, computes the MinT reconciliation matrix, and evaluates on the validation set.

### 3. Evaluate

```bash
python scripts/evaluate.py --config configs/default.yaml
```

Computes WRMSSE, MASE, sMAPE, coverage, interval scores, and coherence metrics on the test set.

### 4. Generate Forecasts

```bash
python scripts/predict.py --config configs/default.yaml --horizon 28
```

Produces reconciled point forecasts and prediction intervals for all 693 series over the specified horizon.

---

## Configuration

Key parameters in [`configs/default.yaml`](configs/default.yaml):

| Parameter | Default | Description |
|:----------|:--------|:-----------|
| `data.train_days` | 300 | Number of training days |
| `data.validation_days` | 28 | Validation horizon |
| `data.test_days` | 28 | Test horizon |
| `models.statistical` | ETS + ARIMA | Base model specifications |
| `ensemble.weights` | [0.5, 0.5] | Model combination weights |
| `reconciliation.method` | `probabilistic_mint` | Reconciliation algorithm |
| `reconciliation.weights` | `wls` | MinT weight estimation method |
| `reconciliation.lambda_reg` | 0.01 | Regularization for W matrix inversion |

See [`configs/ablation.yaml`](configs/ablation.yaml) for OLS baseline configuration.

---

## Project Structure

```
├── configs/                  # YAML configuration files
│   ├── default.yaml          # Default training configuration
│   └── ablation.yaml         # Ablation study (OLS baseline)
├── scripts/
│   ├── generate_synthetic_data.py   # Synthetic M5 data generator
│   ├── train.py              # Training entry point
│   ├── evaluate.py           # Evaluation entry point
│   └── predict.py            # Inference entry point
├── src/hierarchical_forecast_reconciliation_with_uncertainty_quantification/
│   ├── data/
│   │   ├── loader.py         # M5DataLoader, hierarchy builder
│   │   └── preprocessing.py  # Log1p, scaling, outlier handling, S matrix
│   ├── models/
│   │   └── model.py          # StatisticalForecaster, ProbabilisticReconciler, Ensemble
│   ├── training/
│   │   └── trainer.py        # HierarchicalForecastTrainer with MLflow integration
│   └── evaluation/
│       └── metrics.py        # WRMSSE, MASE, sMAPE, coverage, coherence
├── tests/                    # Unit and integration tests
├── notebooks/                # Exploratory analysis notebooks
├── results/                  # Serialized metrics and summaries
├── artifacts/                # Saved models and configurations
├── data/                     # Generated synthetic datasets
├── pyproject.toml            # Package configuration and dependencies
├── requirements.txt          # Pinned dependency list
└── README.md
```

---

## Future Directions

- **Real M5 Data**: Evaluate on the actual M5 competition dataset from Kaggle for realistic benchmarking
- **Deep Learning Models**: Integrate Temporal Fusion Transformers (TFT) and N-BEATS as additional ensemble members
- **Sample-Based Reconciliation**: Replace linear interval transformation with sample-based methods to improve prediction interval calibration
- **Adaptive Ensemble Weights**: Tune ETS/ARIMA weights using validation performance via Optuna
- **Cross-Validation**: Implement temporal cross-validation for more robust metric estimation

---

## References

1. Wickramasuriya, S.L., Athanasopoulos, G., & Hyndman, R.J. (2019). Optimal forecast reconciliation for hierarchical and grouped time series through trace minimization. *Journal of the American Statistical Association*, 114(526), 804--819.

2. Hyndman, R.J., Ahmed, R.A., Athanasopoulos, G., & Shang, H.L. (2011). Optimal combination forecasts for hierarchical time series. *Computational Statistics & Data Analysis*, 55(9), 2579--2589.

3. Makridakis, S., Spiliotis, E., & Assimakopoulos, V. (2022). M5 accuracy competition: Results, findings, and conclusions. *International Journal of Forecasting*, 38(4), 1346--1364.

4. Panagiotelis, A., Gamakumara, P., Athanasopoulos, G., & Hyndman, R.J. (2023). Probabilistic forecast reconciliation: Properties, evaluation and score optimisation. *European Journal of Operational Research*, 306(2), 693--706.

---

## License

MIT License -- Copyright (c) 2026 Alireza Shojaei. See [LICENSE](LICENSE) for details.
