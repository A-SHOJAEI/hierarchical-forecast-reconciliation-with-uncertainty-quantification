# Default configuration for hierarchical forecast reconciliation
# All paths are relative to project root

# Data configuration
data:
  # M5 dataset paths
  path: "data/m5"
  calendar_path: "data/m5/calendar.csv"
  prices_path: "data/m5/sell_prices.csv"
  sales_train_path: "data/m5/sales_train_evaluation.csv"
  sales_test_path: "data/m5/sales_train_validation.csv"

  # Preprocessing parameters (adjusted for synthetic 365-day dataset)
  train_days: 300
  validation_days: 28
  test_days: 28
  min_nonzero_ratio: 0.1

  # Aggregation levels for hierarchical reconciliation
  aggregation_levels:
    - "total"
    - "state"
    - "store"
    - "cat"
    - "dept"
    - "state_cat"
    - "state_dept"
    - "store_cat"
    - "store_dept"
    - "item"
    - "item_store"

# Model configuration
models:
  # Statistical models
  statistical:
    ets:
      seasonal_periods: 7
      error: "add"
      trend: "add"
      seasonal: "add"
      use_boxcox: false
      remove_bias: true

    arima:
      seasonal_order: [1, 1, 1, 7]
      maxiter: 50
      method: "lbfgs"

  # Deep learning models (disabled by default for stability)
  deep_learning: {}

# Reconciliation configuration
reconciliation:
  method: "probabilistic_mint"
  weights: "wls"
  covariance_type: "sample"
  lambda_reg: 0.01
  preserve_uncertainty: true
  coherence_penalty: 1.0

# Ensemble configuration (statistical only)
ensemble:
  weights:
    ets: 0.5
    arima: 0.5
  combination_method: "weighted_average"
  uncertainty_propagation: "bootstrap"
  n_bootstrap_samples: 1000

# Training configuration
training:
  batch_size: 64
  max_epochs: 200
  early_stopping_patience: 20
  learning_rate: 0.001
  weight_decay: 0.00000001
  gradient_clip_val: 0.1

  # Validation strategy
  validation_split: 0.2
  cross_validation_folds: 5

  # Checkpointing
  save_top_k: 3
  monitor: "val_loss"
  mode: "min"

  # MLflow tracking
  experiment_name: "hierarchical_forecast_reconciliation"
  run_name: null
  tracking_uri: "mlruns"

# Evaluation configuration
evaluation:
  metrics:
    - "WRMSSE"
    - "MASE"
    - "sMAPE"
    - "coverage_90"
    - "coverage_95"
    - "reconciliation_coherence"

  # Significance testing
  statistical_tests:
    - "dm_test"

  confidence_level: 0.05

# Hyperparameter optimization
optimization:
  method: "optuna"
  n_trials: 10
  timeout: 3600

  # Parameters to optimize
  search_space:
    reconciliation_lambda_reg: [0.001, 0.1]

# Logging configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/training.log"
  console: true

# Reproducibility
random_seed: 42
torch_seed: 42
numpy_seed: 42
